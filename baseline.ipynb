{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Подключение библиотек и скриптов**","metadata":{}},{"cell_type":"markdown","source":"# Курсовая работа \"Предсказание стоимости дома\"","metadata":{}},{"cell_type":"markdown","source":"для начала подгружаем все необходимые библиотеки и данные","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score as r2\nfrom sklearn.model_selection import KFold, GridSearchCV\nfrom datetime import datetime\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nmatplotlib.rcParams.update({'font.size': 14})\n\nTRAIN_DATASET_PATH = '/kaggle/input/real-estate-price-prediction-moscow/train.csv'\nTEST_DATASET_PATH = '/kaggle/input/real-estate-price-prediction-moscow/test.csv'\n\ntrain_df = pd.read_csv(TRAIN_DATASET_PATH)\ntest_df = pd.read_csv(TEST_DATASET_PATH)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"после того, как мы подгрузили данные надо немного поразмашлять что они из себя представляют, какую ценность игграют и что вообще с ними можно сделать. Начнём с ID, ID вещь очень хорошая, но в моей курсовой абсолютно бессмысленная, так как у каждой квартиры он индивидуальный и никакой тайной зависимости цены - айдишника очевидно не будет. DistrictID также сам по себе важной информацией не является, но с помощью него мы можем узнать \"плотность\" домов в районе, что уже может быть довольно значимым признаком. Rooms, Square, LifeSquare, KitchenSquare очевидно важные признаки как и HouseYear. Этаж и количество этажей в доме не всегда влияют на цену из ходя из моего жизненного опыта, поэтому можно будет попробывать сделать предсказание без этих признаков. Про признаки экологии и социальных показателей местности мы не знаем ничего, поэтому о значимости этого признака мало что понимаем. Также можно предположить, что признаки экологии и наличии магазино с тц могут быть важными.","metadata":{}},{"cell_type":"markdown","source":"**Описание датасета**\n\n* **Id** - идентификационный номер квартиры\n* **DistrictId** - идентификационный номер района\n* **Rooms** - количество комнат\n* **Square** - площадь\n* **LifeSquare** - жилая площадь\n* **KitchenSquare** - площадь кухни\n* **Floor** - этаж\n* **HouseFloor** - количество этажей в доме\n* **HouseYear** - год постройки дома\n* **Ecology_1, Ecology_2, Ecology_3** - экологические показатели местности\n* **Social_1, Social_2, Social_3** - социальные показатели местности\n* **Healthcare_1, Helthcare_2** - показатели местности, связанные с охраной здоровья\n* **Shops_1, Shops_2** - показатели, связанные с наличием магазинов, торговых центров\n* **Price** - цена квартиры","metadata":{}},{"cell_type":"code","source":"test_df.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Строк в трейне:', train_df.shape[0])\nprint('Строк в тесте', test_df.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Приведём признаки ID и DistrictId к строковому типу, чтобы они не мешали модели","metadata":{}},{"cell_type":"code","source":"train_df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['Id'] = train_df['Id'].astype(str)\ntrain_df['DistrictId'] = train_df['DistrictId'].astype(str)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. EDA  <a class='anchor' id='eda'>\nТеперь надо провести работу над данными, найти возможные выбросы,заполнить пропуски и сгенерировать новые признаки","metadata":{}},{"cell_type":"markdown","source":"**Целевая переменная**\nначнём с изучения адекватности целевой переменной, из графика видно, что цена выглядит адекватно(очень дешёвых и очень дорогих домов мало, а домов средней цены много)","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (16, 8))\n\ntrain_df['Price'].hist(bins=30)\nplt.ylabel('Count')\nplt.xlabel('Price')\n\nplt.title('Target distribution')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Далее визуализируем наши данные, чтобы увидеть аномальные значения в некоторых признаках","metadata":{}},{"cell_type":"code","source":"train_df.hist(figsize=(30, 30), bins=20, grid=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" Сразу видно, что потенциальные выбросы имеются в признаках:\n-Rooms\n-HouseFloor\n-HouseYear\n-KitchenSquare\n-Square\n-LifeSquare\nМожно сделать такой вывод, потому что в данных есть значения, которые сильно отличаются от большинства значений\n","metadata":{}},{"cell_type":"markdown","source":"Начнём обрабатывать выбросы с признака Rooms\nПосмотри сколько каких значений есть в этом признаке:","metadata":{}},{"cell_type":"code","source":"train_df['Rooms'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Зачения больше шести комнат будем считать выбросами, таких квартир три\nТакже видим, что есть квартиры с нулём комнат, в вебинаре сказали, что это возможно студии и предложили заменить их на однокомнатную квартиру, но я думаю, что полезней будет оставить 0, потому что возможно с такой идеей ити данные и генирились, поэтому такое значение я оставлю","metadata":{}},{"cell_type":"markdown","source":"Пометим изменённые данные единичкой","metadata":{}},{"cell_type":"code","source":"train_df['Rooms_outlier'] = 0\ntrain_df.loc[ (train_df['Rooms'] > 6), 'Rooms_outlier'] = 1\ntrain_df.loc[train_df['Rooms'] > 6, 'Rooms'] = train_df['Rooms'].median()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Квартиры с кол-вом комнат больше шести заменим на медиану","metadata":{}},{"cell_type":"code","source":"train_df['Rooms'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Далее разберёмся с параметром KitchenSquare","metadata":{}},{"cell_type":"code","source":"train_df['KitchenSquare'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Тут мы видим аномально большие значения, которые скорее всего выбросы, я заменю их на медианы, кухни с площадью 1 квадратный метр можно считать кухнями, которые совместили с другими комнатами, поэтому я не буду их заменять, возможно это важная информация","metadata":{}},{"cell_type":"markdown","source":"Пометим квартиры, которым собираемся менять площадь кухни и заменим её","metadata":{}},{"cell_type":"code","source":"train_df['KitchenSquare_outlier'] = 0\ntrain_df.loc[ (train_df['KitchenSquare'] > 18), 'Rooms_outlier'] = 1\ntrain_df.loc[train_df['KitchenSquare'] > 18, 'KitchenSquare'] = train_df['KitchenSquare'].median()\ntrain_df['KitchenSquare'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"теперь посмотрим на такие параметры как этаж и кол-во этажей в доме, первый баг, который надо исправить, это что-то сделать с квартирами, у которых этаж больше, чем всего этажей в доме, я заменил их на максимальный этаж в доме, пометив эти квартиры. Далее я принял за выбросы дома с кол-вом этажей больше 50 и  0, 0 при этом заменил на 1, а больше 50 - на медиану.","metadata":{}},{"cell_type":"code","source":"train_df['HouseFloor'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['HouseFloor']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['HouseFloor_outlier'] = 0\ntrain_df.loc[train_df['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1\ntrain_df.loc[train_df['HouseFloor'] > 50, 'HouseFloor_outlier'] = 1\ntrain_df.loc[train_df['HouseFloor'] > 50, 'HouseFloor_outlier'] = train_df['HouseFloor'].median()\ntrain_df.loc[train_df['HouseFloor'] == 0, 'HouseFloor_outlier'] = train_df['HouseFloor'].median()\nfloor_outliers = train_df.loc[train_df['Floor'] > train_df['HouseFloor']].index\ntrain_df.loc[floor_outliers, 'Floor'] = train_df.loc[floor_outliers, 'HouseFloor']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(train_df['Floor'] > train_df['HouseFloor']).sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Теперь пофиксим анамалии в дате постройки дома, тут всё более менее хорошо, но некторые дома построены в будующем, тут я заменил дату постройки на текущий год","metadata":{}},{"cell_type":"code","source":"train_df['HouseYear'].sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"current_year = datetime.now().year        \ntrain_df['HouseYear_outlier'] = 0\ntrain_df.loc[train_df['HouseYear'] > current_year, 'HouseYear_outlier'] = 1\ntrain_df.loc[train_df['HouseYear'] > current_year, 'HouseYear'] = current_year","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"с площадью дома и сжилой площадью дома я поступил аналогично площади кухни, а именно принял за выбросы значения меньше 8ми и больше 300от, но заменил их не на медиану, а на квантили 25ти и 75ти процентов","metadata":{}},{"cell_type":"code","source":"train_df['Square'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['Square_outlier'] = 0\ntrain_df.loc[train_df['Square'] < 8, 'Square_outlier'] = 1\ntrain_df.loc[train_df['Square'] > 300, 'Square_outlier'] = 1\ntrain_df.loc[train_df['Square'] > 300, 'Square'] = train_df['Square'].quantile(.25)\ntrain_df.loc[train_df['Square'] < 8, 'Square'] = train_df['Square'].quantile(.75)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['LifeSquare'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['LifeSquare_outlier'] = 0\ntrain_df.loc[train_df['LifeSquare'] < 8, 'LifeSquare_outlier'] = 1\ntrain_df.loc[train_df['LifeSquare'] > 300, 'LifeSquare_outlier'] = 1\ntrain_df.loc[train_df['LifeSquare'] > 300, 'LifeSquare'] = train_df['LifeSquare'].quantile(.25)\ntrain_df.loc[train_df['LifeSquare'] < 8, 'LifeSquare'] = train_df['LifeSquare'].quantile(.75)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Окей, если с выбросами всё, то надо обработать пропуски, для начало посмотрим сколько их","metadata":{}},{"cell_type":"code","source":"train_df.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Видно, что пропуски в жилой площади и в признаке экологии, в признаке экологии почти половина строчек пустые, поэтому этот признак можно просто выкинуть, а жилую площадь я стандартно заменю на медиану","metadata":{}},{"cell_type":"code","source":"train_df.drop('Healthcare_1', axis=1, inplace=True)\ntrain_df.loc[train_df['LifeSquare'].isna() , 'LifeSquare_outlier'] = 1\ntrain_df.loc[train_df['LifeSquare'].isna() , 'LifeSquare'] = train_df['LifeSquare'].median()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"теперь, когда все данные в нормальном виде, можно сделать новые фичи","metadata":{}},{"cell_type":"markdown","source":"Для начала заменим бинарные признаки на числовые","metadata":{}},{"cell_type":"code","source":"binary_to_numbers = {'A': 0, 'B': 1}\ntrain_df['Ecology_2'] = train_df['Ecology_2'].replace(binary_to_numbers)\ntrain_df['Ecology_3'] = train_df['Ecology_3'].replace(binary_to_numbers)\ntrain_df['Shops_2'] = train_df['Shops_2'].replace(binary_to_numbers)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Сгенерим признак плотности домов районе(насколько много домов в этом районе)","metadata":{}},{"cell_type":"code","source":"district_size = train_df['DistrictId'].value_counts().reset_index()\\\n                    .rename(columns={'index':'DistrictId', 'DistrictId':'DistrictSize'})\ntrain_df = train_df.merge(district_size, on='DistrictId', how='left')\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.merge(district_size, on='DistrictId', how='left')\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"создадим новый признак средняя цена на районе","metadata":{}},{"cell_type":"code","source":"med_price_by_district = train_df.groupby(['DistrictId', 'Rooms'], as_index=False).agg({'Price':'median'})\\\n                            .rename(columns={'Price':'MedPriceByDistrict'})\ntrain_df = train_df.merge(med_price_by_district, on=['DistrictId', 'Rooms'], how='left')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"теперь все эти изменения занесём в класс","metadata":{}},{"cell_type":"code","source":"class DataPreprocessing:\n    \"\"\"Подготовка исходных данных\"\"\"\n\n    def __init__(self):\n        \"\"\"Параметры класса\"\"\"\n        self.medians=None\n        self.kitchen_square_quantile = None\n        \n    def fit(self, X):\n        \"\"\"Сохранение статистик\"\"\"       \n        # Расчет медиан\n        self.medians = X.median()\n        self.kitchen_square_quantile = X['KitchenSquare'].quantile(.975)\n    \n    def transform(self, X):\n        \"\"\"Трансформация данных и генерация новых фич\"\"\"\n\n        # Rooms\n        X['Rooms_outlier'] = 0\n        X.loc[ (X['Rooms'] > 6), 'Rooms_outlier'] = 1\n        X.loc[X['Rooms'] > 6, 'Rooms'] = X['Rooms'].median()\n        \n        # KitchenSquare\n        X['KitchenSquare_outlier'] = 0\n        X.loc[ (X['KitchenSquare'] > 18), 'Rooms_outlier'] = 1\n        X.loc[X['KitchenSquare'] > 18, 'KitchenSquare'] = X['KitchenSquare'].median()\n        \n        # HouseFloor, Floor\n        X['HouseFloor_outlier'] = 0\n        X.loc[X['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1\n        X.loc[X['HouseFloor'] > 50, 'HouseFloor_outlier'] = 1\n        X.loc[X['HouseFloor'] > 50, 'HouseFloor_outlier'] = X['HouseFloor'].median()\n        X.loc[X['HouseFloor'] == 0, 'HouseFloor_outlier'] = X['HouseFloor'].median()\n        floor_outliers = X.loc[X['Floor'] > X['HouseFloor']].index\n        X.loc[floor_outliers, 'Floor'] = X.loc[floor_outliers, 'HouseFloor']\n        \n        # HouseYear\n        current_year = datetime.now().year        \n        X['HouseYear_outlier'] = 0\n        X.loc[X['HouseYear'] > current_year, 'HouseYear_outlier'] = 1\n        X.loc[X['HouseYear'] > current_year, 'HouseYear'] = current_year\n\n        X['Square_outlier'] = 0\n        X.loc[X['Square'] < 8, 'Square_outlier'] = 1\n        X.loc[X['Square'] > 300, 'Square_outlier'] = 1\n        X.loc[X['Square'] > 300, 'Square'] = X['Square'].quantile(.25)\n        X.loc[X['Square'] < 8, 'Square'] = X['Square'].quantile(.75)\n\n        X['LifeSquare_outlier'] = 0\n        X.loc[X['LifeSquare'] < 8, 'LifeSquare_outlier'] = 1\n        X.loc[X['LifeSquare'] > 300, 'LifeSquare_outlier'] = 1\n        X.loc[X['LifeSquare'] > 300, 'LifeSquare'] = X['LifeSquare'].quantile(.25)\n        X.loc[X['LifeSquare'] < 8, 'LifeSquare'] = X['LifeSquare'].quantile(.75)\n\n        X.drop('Healthcare_1', axis=1, inplace=True)\n        X.loc[X['LifeSquare'].isna() , 'LifeSquare_outlier'] = 1\n        X.loc[X['LifeSquare'].isna() , 'LifeSquare'] = X['LifeSquare'].median()\n\n        binary_to_numbers = {'A': 0, 'B': 1}\n        X['Ecology_2'] = X['Ecology_2'].replace(binary_to_numbers)\n        X['Ecology_3'] = X['Ecology_3'].replace(binary_to_numbers)\n        X['Shops_2'] = X['Shops_2'].replace(binary_to_numbers)\n\n        district_size = X['DistrictId'].value_counts().reset_index()\\\n                    .rename(columns={'index':'DistrictId', 'DistrictId':'DistrictSize'})\n        X = X.merge(district_size, on='DistrictId', how='left')\n        \n        \n        X.fillna(self.medians, inplace=True)\n        \n        return X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5. Отбор признаков  <a class='anchor' id='feature_selection'>","metadata":{}},{"cell_type":"code","source":"train_df.columns.tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_names = ['Rooms', 'Square', 'LifeSquare', 'KitchenSquare', 'Floor', 'HouseFloor', 'HouseYear',\n                 'Ecology_1', 'Ecology_2', 'Ecology_3', 'Social_1', 'Social_2', 'Social_3',\n                 'Helthcare_2', 'Shops_1', 'Shops_2']\n\nnew_feature_names = ['Rooms_outlier', 'HouseFloor_outlier', 'HouseYear_outlier',  'DistrictSize']\n\ntarget_name = 'Price'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"разобьем анши данные на тренировочные и валидационные","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(TRAIN_DATASET_PATH)\ntest_df = pd.read_csv(TEST_DATASET_PATH)\n\nX = train_df.drop(columns=target_name)\ny = train_df[target_name]\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, shuffle=True, random_state=21)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"трансформируем наши данные","metadata":{}},{"cell_type":"code","source":"preprocessor = DataPreprocessing()\npreprocessor.fit(X_train)\n\nX_train = preprocessor.transform(X_train)\nX_valid = preprocessor.transform(X_valid)\ntest_df = preprocessor.transform(test_df)\n\nX_train.shape, X_valid.shape, test_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_train[feature_names + new_feature_names]\nX_valid = X_valid[feature_names + new_feature_names]\ntest_df = test_df[feature_names + new_feature_names]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.isna().sum().sum(), X_valid.isna().sum().sum(), test_df.isna().sum().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7. Построение модели  <a class='anchor' id='modeling'>","metadata":{}},{"cell_type":"markdown","source":"**Обучение**","metadata":{}},{"cell_type":"code","source":"def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\n    print(\"Train R2:\\t\" + str(round(r2(train_true_values, train_pred_values), 3)))\n    print(\"Test R2:\\t\" + str(round(r2(test_true_values, test_pred_values), 3)))\n    \n    plt.figure(figsize=(18,10))\n    \n    plt.subplot(121)\n    sns.scatterplot(x=train_pred_values, y=train_true_values)\n    plt.xlabel('Predicted values')\n    plt.ylabel('True values')\n    plt.title('Train sample prediction')\n    \n    plt.subplot(122)\n    sns.scatterplot(x=test_pred_values, y=test_true_values)\n    plt.xlabel('Predicted values')\n    plt.ylabel('True values')\n    plt.title('Test sample prediction')\n\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Перебрав разные модели, я пришёл к выводу, что BoostingRegressor лучшее решение при таких параметрах","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\ngb_model = GradientBoostingRegressor(random_state=21, criterion='mse', max_depth=3, min_samples_leaf=25, n_estimators=200)\ngb_model.fit(X_train, y_train)\ny_train_preds = gb_model.predict(X_train)\ny_test_preds = gb_model.predict(X_valid)\n\nevaluate_preds(y_train, y_train_preds, y_valid, y_test_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 8. Прогнозирование на тестовом датасете  <a class='anchor' id='prediction'>\n\n1. Выполнить для тестового датасета те же этапы обработки и постронияния признаков\n2. Не потерять и не перемешать индексы от примеров при построении прогнозов\n3. Прогнозы должны быть для все примеров из тестового датасета (для всех строк)","metadata":{}},{"cell_type":"code","source":"test_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.read_csv('/kaggle/input/real-estate-price-prediction-moscow/sample_submission.csv')\nsubmit.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = gb_model.predict(test_df)\npredictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit['Price'] = predictions\nsubmit.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit.to_csv('rf_submit.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}